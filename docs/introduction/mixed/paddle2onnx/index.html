<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-introduction/mixed/paddle2onnx" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Paddle2ONNX模型转化与预测 | WinUI</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://your-domain.com/introduction/mixed/paddle2onnx"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Paddle2ONNX模型转化与预测 | WinUI"><meta data-rh="true" name="description" content="本章节介绍 PaddleOCR 模型如何转化为 ONNX 模型，并在 小友+ 中使用。"><meta data-rh="true" property="og:description" content="本章节介绍 PaddleOCR 模型如何转化为 ONNX 模型，并在 小友+ 中使用。"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-domain.com/introduction/mixed/paddle2onnx"><link data-rh="true" rel="alternate" href="https://your-domain.com/introduction/mixed/paddle2onnx" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://your-domain.com/introduction/mixed/paddle2onnx" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"系统配置要求","item":"https://your-domain.com/introduction/"},{"@type":"ListItem","position":2,"name":"Paddle2ONNX模型转化与预测","item":"https://your-domain.com/introduction/mixed/paddle2onnx"}]}</script><link rel="stylesheet" href="/assets/css/styles.0192d20b.css">
<script src="/assets/js/runtime~main.4e65172f.js" defer="defer"></script>
<script src="/assets/js/main.c7f9548e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="./introduction/mixed/inference_results/lite_demo_onnx.png"><link rel="preload" as="image" href="./introduction/mixed/inference_results/lite_demo_paddle.png"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">WinUI 文档</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">文档</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/shelllet/WinUi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="切换浅色/暗黑模式（当前为system mode）"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/CHANGELOG"><span title="[0.49](https://github.com/shelllet/winui/compare/main...dev) (2026-xx-xx)" class="linkLabel_WmDU">[0.49](https://github.com/shelllet/winui/compare/main...dev) (2026-xx-xx)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="小友+" class="linkLabel_WmDU">小友+</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/actions/"><span title="动作" class="categoryLinkLabel_W154">动作</span></a><button aria-label="展开侧边栏分类 &#x27;动作&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/enums/AncestorWindow"><span title="enums" class="categoryLinkLabel_W154">enums</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/introduction/"><span title="系统配置要求" class="categoryLinkLabel_W154">系统配置要求</span></a><button aria-label="折叠侧边栏分类 &#x27;系统配置要求&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/android/uiautomatorviewer"><span title="android" class="categoryLinkLabel_W154">android</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/installation/installed_by_exe"><span title="installation" class="categoryLinkLabel_W154">installation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/introduction/mixed/CUDA"><span title="mixed" class="categoryLinkLabel_W154">mixed</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/introduction/mixed/CUDA"><span title="CUDA" class="linkLabel_WmDU">CUDA</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/introduction/mixed/cuDNN"><span title="cuDNN 和 CUDA 版本对应关系" class="linkLabel_WmDU">cuDNN 和 CUDA 版本对应关系</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/introduction/mixed/glob"><span title="Glob模式" class="linkLabel_WmDU">Glob模式</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/introduction/mixed/paddle2onnx"><span title="Paddle2ONNX模型转化与预测" class="linkLabel_WmDU">Paddle2ONNX模型转化与预测</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/introduction/mixed/wildcard"><span title="通配符" class="linkLabel_WmDU">通配符</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/setting/action_group_setting"><span title="setting" class="categoryLinkLabel_W154">setting</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/tesseract/Data-Files"><span title="tesseract" class="categoryLinkLabel_W154">tesseract</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/webdriver/browser_directory"><span title="webdriver" class="categoryLinkLabel_W154">webdriver</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/introduction/workflow/action"><span title="workflow" class="categoryLinkLabel_W154">workflow</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/network/openwrt_dns"><span title="network" class="categoryLinkLabel_W154">network</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/types/ActionChains"><span title="types" class="categoryLinkLabel_W154">types</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/introduction/"><span>系统配置要求</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">mixed</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Paddle2ONNX模型转化与预测</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>Paddle2ONNX模型转化与预测</h1></header>
<p>本章节介绍 PaddleOCR 模型如何转化为 ONNX 模型，并在 <em>小友+</em> 中使用。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-环境准备">1. 环境准备<a href="#1-环境准备" class="hash-link" aria-label="1. 环境准备的直接链接" title="1. 环境准备的直接链接" translate="no">​</a></h2>
<p>需要准备 Python、Paddle、 PaddleOCR、Paddle2ONNX 模型转化环境，和 ONNXRuntime 预测环境。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="python">Python<a href="#python" class="hash-link" aria-label="Python的直接链接" title="Python的直接链接" translate="no">​</a></h3>
<ol>
<li class="">下载 Python 安装包，本章节使用 <code>3.12.9</code> 版本，下载链接:<a href="https://www.python.org/ftp/python/3.12.9/python-3.12.9-amd64.exe" target="_blank" rel="noopener noreferrer" class="">https://www.python.org/ftp/python/3.12.9/python-3.12.9-amd64.exe</a>。</li>
</ol>
<ul>
<li class="">打开 Python 官方下载页面 <a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer" class="">https://www.python.org/downloads/</a>。</li>
<li class="">页面会根据你的系统自动推荐合适的 Python 版本。通常建议选择最新的稳定版本，在页面中找到“Download Python x.x.x”（x.x.x 代表具体版本号）按钮并点击。若你的 Windows 系统是 64 位，下载 64 - bit 的安装包；若为 32 位系统，则下载 32 - bit 的安装包。</li>
</ul>
<ol start="2">
<li class="">运行安装程序</li>
</ol>
<ul>
<li class="">找到下载好的 <code>.exe</code> 格式的安装文件，双击运行。</li>
<li class="">在弹出的安装界面中，注意勾选“Add Python x.x to PATH”选项，这个操作能自动将 Python 可执行文件路径添加到系统的环境变量中，之后你就能在命令提示符里直接使用 Python 命令。</li>
<li class="">你可以选择“Install Now”进行默认安装，也能点击“Customize installation”来自定义安装路径和组件。若不确定如何选择，建议直接点击“Install Now”。</li>
<li class="">等待安装过程完成，这可能需要一些时间，取决于你的系统性能。</li>
</ul>
<ol start="3">
<li class="">验证 Python 安装</li>
</ol>
<ul>
<li class="">按下 <code>Win + R</code> 组合键，打开“运行”对话框，输入 <code>cmd</code> 并回车，以此打开命令提示符窗口。</li>
<li class="">在命令提示符中输入 <code>python --version</code> 并回车。若安装成功，会显示所安装的 Python 版本号，例如 <code>Python 3.11.5</code>。</li>
</ul>
<ol start="4">
<li class="">
<p>验证 pip 安装
<code>pip</code> 是 Python 的包管理工具，一般会随 Python 一起安装。在命令提示符中输入 <code>pip --version</code> 并回车，若安装成功，会显示 <code>pip</code> 的版本信息以及对应的 Python 版本，例如 <code>pip 23.3.1 from C:\Python311\Lib\site-packages\pip (python 3.11)</code>。</p>
</li>
<li class="">
<p>更新 pip（可选）
为保证能使用 <code>pip</code> 的最新特性和修复已知问题，可在命令提示符中运行以下命令来更新 <code>pip</code>：</p>
</li>
</ol>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m pip install --upgrade pip</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="虚拟环境">虚拟环境<a href="#虚拟环境" class="hash-link" aria-label="虚拟环境的直接链接" title="虚拟环境的直接链接" translate="no">​</a></h3>
<p>在 Python 开发中，虚拟环境是一个非常有用的工具，它可以为每个项目创建独立的 Python 运行环境，避免不同项目之间的依赖冲突。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="使用-venv-模块python-标准库自带">使用 <code>venv</code> 模块（Python 标准库自带）<a href="#使用-venv-模块python-标准库自带" class="hash-link" aria-label="使用-venv-模块python-标准库自带的直接链接" title="使用-venv-模块python-标准库自带的直接链接" translate="no">​</a></h3>
<p><code>venv</code> 是 Python 3.3 及以上版本标准库中自带的虚拟环境创建工具，使用起来简单方便。</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="步骤">步骤<a href="#步骤" class="hash-link" aria-label="步骤的直接链接" title="步骤的直接链接" translate="no">​</a></h4>
<ol>
<li class=""><strong>打开命令行工具</strong>：在 Windows 系统中可以使用命令提示符（CMD）或 PowerShell。</li>
<li class=""><strong>创建虚拟环境</strong>：在命令行中进入你想要创建虚拟环境的目录，然后运行以下命令：</li>
</ol>
<div class="language-PowerShell language-powershell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-powershell codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd d:\onnx</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m venv myenv</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># PowerShell</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">.\myenv\Scripts\Activate.ps1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># CMD</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># .\myenv\Scripts\activate.bat</span><br></span></code></pre></div></div>
<p>其中 <code>myenv</code> 是你要创建的虚拟环境的名称，你可以根据需要进行修改。</p>
<ol start="3">
<li class=""><strong>激活虚拟环境</strong>：<!-- -->
<ul>
<li class=""><strong>Windows（CMD）</strong>：</li>
</ul>
</li>
</ol>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">myenv\Scripts\activate.bat</span><br></span></code></pre></div></div>
<ul>
<li class=""><strong>Windows（PowerShell）</strong>：</li>
</ul>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">myenv\Scripts\Activate.ps1</span><br></span></code></pre></div></div>
<p>激活虚拟环境后，命令行提示符前面会显示虚拟环境的名称，表明你已经成功进入该虚拟环境。</p>
<ol start="4">
<li class=""><strong>安装依赖包</strong>：在虚拟环境中，你可以使用 <code>pip</code> 安装项目所需的依赖包，例如：</li>
</ol>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install requests</span><br></span></code></pre></div></div>
<ol start="5">
<li class=""><strong>退出虚拟环境</strong>：当你完成开发工作后，可以在命令行中运行以下命令退出虚拟环境：</li>
</ol>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">deactivate</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="paddle">Paddle<a href="#paddle" class="hash-link" aria-label="Paddle的直接链接" title="Paddle的直接链接" translate="no">​</a></h3>
<p>在使用 <code>pip install paddlepaddle</code> 安装 PaddlePaddle（以下简称 Paddle）时，有一些要点需要注意，下面为你详细介绍不同环境下的安装步骤和注意事项。</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-选择合适的-paddle-版本">1. 选择合适的 Paddle 版本<a href="#1-选择合适的-paddle-版本" class="hash-link" aria-label="1. 选择合适的 Paddle 版本的直接链接" title="1. 选择合适的 Paddle 版本的直接链接" translate="no">​</a></h4>
<p>Paddle 有 CPU 版本和 GPU 版本，你需要根据自己的硬件情况选择合适的版本。</p>
<ul>
<li class=""><strong>CPU 版本</strong>：如果你的计算机没有 NVIDIA GPU 或者不需要使用 GPU 进行计算，那么选择 CPU 版本即可。</li>
<li class=""><strong>GPU 版本</strong>：如果你的计算机配备了 NVIDIA GPU，并且想利用 GPU 的计算能力加速训练和推理，那么需要安装 GPU 版本。同时，你还需要安装对应的 CUDA 和 cuDNN 库。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-安装-paddle">2. 安装 Paddle<a href="#2-安装-paddle" class="hash-link" aria-label="2. 安装 Paddle的直接链接" title="2. 安装 Paddle的直接链接" translate="no">​</a></h4>
<h5 class="anchor anchorTargetStickyNavbar_Vzrq" id="cpu-版本安装推荐">CPU 版本安装（推荐）<a href="#cpu-版本安装推荐" class="hash-link" aria-label="CPU 版本安装（推荐）的直接链接" title="CPU 版本安装（推荐）的直接链接" translate="no">​</a></h5>
<p>在命令行中运行以下命令安装 CPU 版本的 Paddle：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple</span><br></span></code></pre></div></div>
<p>这里 <code>-i https://mirror.baidu.com/pypi/simple</code> 是指定使用百度的 PyPI 镜像源，这样可以加快下载速度。</p>
<h5 class="anchor anchorTargetStickyNavbar_Vzrq" id="gpu-版本安装">GPU 版本安装<a href="#gpu-版本安装" class="hash-link" aria-label="GPU 版本安装的直接链接" title="GPU 版本安装的直接链接" translate="no">​</a></h5>
<p>如果你要安装 GPU 版本，需要先确认你的 CUDA 和 cuDNN 版本，通过执行命令 <strong>nvidia-smi.exe</strong> 查看 CUDA 版本， 查看输出：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">nvidia-smi.exe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Mon Apr 21 14:18:12 2025</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">+-----------------------------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|-----------------------------------------+------------------------+----------------------+</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|                                         |                        |               MIG M. |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|=========================================+========================+======================|</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">| N/A   48C    P0             13W /  140W |       0MiB /   8188MiB |      0%      Default |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|                                         |                        |                  N/A |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">+-----------------------------------------+------------------------+----------------------+</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">+-----------------------------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">| Processes:                                                                              |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|        ID   ID                                                               Usage      |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|=========================================================================================|</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">|  No running processes found                                                             |</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">+-----------------------------------------------------------------------------------------+</span><br></span></code></pre></div></div>
<p>CUDA 参考 <a class="" href="/introduction/mixed/CUDA">Windows 系统上安装 CUDA</a> 安装，检查相应的<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\bin</code> 路径是否加入到环境变量<code>PATH</code>中。</p>
<p><a class="" href="/introduction/mixed/cuDNN">对应的cuDNN</a> 版本下载：<a href="https://developer.nvidia.com/cudnn-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exe_local" target="_blank" rel="noopener noreferrer" class="">https://developer.nvidia.com/cudnn-archive</a>。解压之后 ，同样设置环境变量<code>PATH</code>。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">$env:PATH = &quot;D:\onnx\cudnn-windows-x86_64-8.9.7.29_cuda12-archive\bin;$env:PATH;&quot;</span><br></span></code></pre></div></div>
<p>然后根据版本选择合适的安装命令。例如，如果你使用的是 CUDA 12.0 和 cuDNN 9.8，可以运行以下命令：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install paddlepaddle-gpu==3.1.0.post120 -f https://www.paddlepaddle.org.cn/whl/windows/mkl/avx/stable.html</span><br></span></code></pre></div></div>
<p>其中 <code>2.6.1.post120</code> 表示 Paddle 的版本，<code>120</code> 代表 CUDA 12.0。你可以根据自己的实际情况调整版本号。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-验证安装">4. 验证安装<a href="#4-验证安装" class="hash-link" aria-label="4. 验证安装的直接链接" title="4. 验证安装的直接链接" translate="no">​</a></h3>
<p>安装完成后，你可以在 Python 环境中验证 Paddle 是否安装成功。打开 Python 解释器，输入以下代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> paddle</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">utils</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">run_check</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre></div></div>
<p>如果输出类似 <code>PaddlePaddle is installed successfully!</code> 的信息，说明 Paddle 已经成功安装。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-错误">5. 错误<a href="#5-错误" class="hash-link" aria-label="5. 错误的直接链接" title="5. 错误的直接链接" translate="no">​</a></h3>
<p>当你遇到 No module named &#x27;setuptools&#x27; 错误，意味着 Python 环境里没有安装 setuptools 模块。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install setuptools</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="paddleocr">PaddleOCR<a href="#paddleocr" class="hash-link" aria-label="PaddleOCR的直接链接" title="PaddleOCR的直接链接" translate="no">​</a></h3>
<p>克隆PaddleOCR的仓库，使用 main 分支，并进行安装，由于 PaddleOCR 仓库比较大，git clone 速度比较慢，或使用国内镜像站点下载。</p>
<p>使用虚拟环境：<code>(myenv) PS D:\onnx&gt;</code>。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">git clone  -b main https://github.com/PaddlePaddle/PaddleOCR.git</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PaddleOCR</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m pip install -e .</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="paddle2onnx">Paddle2ONNX<a href="#paddle2onnx" class="hash-link" aria-label="Paddle2ONNX的直接链接" title="Paddle2ONNX的直接链接" translate="no">​</a></h3>
<p>Paddle2ONNX 支持将 PaddlePaddle 模型格式转化到 ONNX 模型格式，算子目前稳定支持导出 ONNX Opset 9~18，部分Paddle算子支持更低的ONNX Opset转换。
更多细节可参考 <a href="https://github.com/PaddlePaddle/Paddle2ONNX/tree/develop" target="_blank" rel="noopener noreferrer" class="">Paddle2ONNX</a>。
使用虚拟环境：<code>(myenv) PS D:\onnx&gt;</code>。</p>
<ul>
<li class="">安装 Paddle2ONNX</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m pip install paddle2onnx==2.0.2rc3</span><br></span></code></pre></div></div>
<ul>
<li class="">安装 ONNXRuntime</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python -m pip install onnxruntime</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-模型转换">2. 模型转换<a href="#2-模型转换" class="hash-link" aria-label="2. 模型转换的直接链接" title="2. 模型转换的直接链接" translate="no">​</a></h2>
<ul>
<li class="">Paddle 模型下载</li>
</ul>
<p>在 <a href="https://www.paddleocr.ai/latest/version3.x/pipeline_usage/OCR.html" target="_blank" rel="noopener noreferrer" class="">模型列表</a> 中下载PaddleOCR提供的预测模型。目前包含 5 种模型，</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><b>文档图像方向分类模块（可选）：</b></summary><div><div class="collapsibleContent_i85q"><table><thead><tr><th>模型</th><th>模型下载链接</th><th>Top-1 Acc（%）</th><th>GPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>CPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>模型存储大小（MB）</th><th>介绍</th></tr></thead><tbody><tr><td>PP-LCNet_x1_0_doc_ori</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-LCNet_x1_0_doc_ori_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-LCNet_x1_0_doc_ori_pretrained.pdparams">训练模型</a></td><td>99.06</td><td>2.62 / 0.59</td><td>3.24 / 1.19</td><td>7</td><td>基于PP-LCNet_x1_0的文档图像分类模型，含有四个类别，即0度，90度，180度，270度</td></tr></tbody></table></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><b>文本图像矫正模块（可选）：</b></summary><div><div class="collapsibleContent_i85q"><table><thead><tr><th>模型</th><th>模型下载链接</th><th>CER </th><th>GPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>CPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>模型存储大小（MB）</th><th>介绍</th></tr></thead><tbody><tr><td>UVDoc</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/UVDoc_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/UVDoc_pretrained.pdparams">训练模型</a></td><td>0.179</td><td>19.05 / 19.05</td><td>- / 869.82</td><td>30.3</td><td>高精度文本图像矫正模型</td></tr></tbody></table></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><b>文本行方向分类模块（可选）：</b></summary><div><div class="collapsibleContent_i85q"><table><thead><tr><th>模型</th><th>模型下载链接</th><th>Top-1 Acc（%）</th><th>GPU推理耗时（ms）</th><th>CPU推理耗时 (ms)</th><th>模型存储大小（MB）</th><th>介绍</th></tr></thead><tbody><tr><td>PP-LCNet_x0_25_textline_ori</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-LCNet_x0_25_textline_ori_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-LCNet_x0_25_textline_ori_pretrained.pdparams">训练模型</a></td><td>98.85</td><td>2.16 / 0.41</td><td>2.37 / 0.73</td><td>0.96</td><td>基于PP-LCNet_x0_25的文本行分类模型，含有两个类别，即0度，180度</td></tr><tr><td>PP-LCNet_x1_0_textline_ori</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-LCNet_x1_0_textline_ori_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-LCNet_x1_0_textline_ori_pretrained.pdparams">训练模型</a></td><td>99.42</td><td>- / -</td><td>2.98 / 2.98</td><td>6.5</td><td>基于PP-LCNet_x1_0的文本行分类模型，含有两个类别，即0度，180度</td></tr></tbody></table></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><b>文本检测模块：</b></summary><div><div class="collapsibleContent_i85q"><table><thead><tr><th>模型</th><th>模型下载链接</th><th>检测Hmean（%）</th><th>GPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>CPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>模型存储大小（MB）</th><th>介绍</th></tr></thead><tbody><tr><td>PP-OCRv5_server_det</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-OCRv5_server_det_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_det_pretrained.pdparams">训练模型</a></td><td>83.8</td><td>89.55 / 70.19</td><td>383.15 / 383.15</td><td>84.3</td><td>PP-OCRv5 的服务端文本检测模型，精度更高，适合在性能较好的服务器上部署</td></tr><tr><td>PP-OCRv5_mobile_det</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-OCRv5_mobile_det_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_mobile_det_pretrained.pdparams">训练模型</a></td><td>79.0</td><td>10.67 / 6.36</td><td>57.77 / 28.15</td><td>4.7</td><td>PP-OCRv5 的移动端文本检测模型，效率更高，适合在端侧设备部署</td></tr></tbody></table></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><b>文本识别模块：</b></summary><div><div class="collapsibleContent_i85q"><table><tr><th>模型</th><th>模型下载链接</th><th>识别 Avg Accuracy(%)</th><th>GPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>CPU推理耗时（ms）<br>[常规模式 / 高性能模式]</th><th>模型存储大小（MB）</th><th>介绍</th></tr><tr><td>PP-OCRv5_server_rec</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/\
PP-OCRv5_server_rec_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_server_rec_pretrained.pdparams">训练模型</a></td><td>86.38</td><td>8.46 / 2.36</td><td>31.21 / 31.21</td><td>81</td><td rowspan="2">PP-OCRv5_rec 是新一代文本识别模型。该模型致力于以单一模型高效、精准地支持简体中文、繁体中文、英文、日文四种主要语言，以及手写、竖版、拼音、生僻字等复杂文本场景的识别。在保持识别效果的同时，兼顾推理速度和模型鲁棒性，为各种场景下的文档理解提供高效、精准的技术支撑。</td></tr><tr><td>PP-OCRv5_mobile_rec</td><td><a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/\
PP-OCRv5_mobile_rec_infer.tar">推理模型</a>/<a href="https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_mobile_rec_pretrained.pdparams">训练模型</a></td><td>81.29</td><td>5.43 / 1.46</td><td>21.20 / 5.32</td><td>16</td></tr></table></div></div></details>
<p><strong>小友+</strong> 中集成了 <code>v5</code> 版本的 <code>Mobile</code> 模型，如果您更注重模型的精度，请选择精度较高的模型。</p>
<ul>
<li class="">文档图像方向分类模块( a.oonx)</li>
<li class="">文本图像矫正模块 b.onnx</li>
<li class="">文本行方向分类模块  c.onnx</li>
<li class="">文本检测模块&gt; d.onxx</li>
<li class="">文本识别模块&gt; e.onnx</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tar xf PP-LCNet_x1_0_doc_ori_infer.tar</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tar xf UVDoc_infer.tar</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tar xf PP-OCRv5_mobile_det_infer.tar</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tar xf PP-LCNet_x1_0_textline_ori_infer.tar</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tar xf PP-OCRv5_mobile_rec_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>使用 Paddle2ONNX 将Paddle静态图模型转换为ONNX模型格式：</p>
<div class="language-PowerShell language-powershell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-powershell codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PP-LCNet_x1_0_doc_ori_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle2onnx --model_dir . `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--model_filename inference.json `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--params_filename inference.pdiparams `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--save_file ./model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--opset_version 18 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_onnx_checker True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--optimize_tool polygraphy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd UVDoc_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle2onnx --model_dir . `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--model_filename inference.json `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--params_filename inference.pdiparams `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--save_file ./model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--opset_version 18 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_auto_update_opset True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_onnx_checker True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--optimize_tool polygraphy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PP-OCRv5_mobile_det_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle2onnx --model_dir . `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--model_filename inference.json `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--params_filename inference.pdiparams `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--save_file ./model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--opset_version 18 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_onnx_checker True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--optimize_tool polygraphy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PP-LCNet_x1_0_textline_ori_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle2onnx --model_dir . `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--model_filename inference.json `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--params_filename inference.pdiparams `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--save_file ./model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--opset_version 18 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_onnx_checker True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--optimize_tool onnxoptimizer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PP-OCRv5_mobile_rec_infer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">paddle2onnx --model_dir . `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--model_filename inference.json `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--params_filename inference.pdiparams `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--save_file ./model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--opset_version 18 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--enable_onnx_checker True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--optimize_tool onnxoptimizer</span><br></span></code></pre></div></div>
<ul>
<li class="">
<p>注意：对于OCR模型，转化过程中必须采用动态shape的形式，否则预测结果可能与直接使用Paddle预测有细微不同。
另外，以下几个模型暂不支持转换为 ONNX 模型：
NRTR、SAR、RARE、SRN</p>
</li>
<li class="">
<p>注意：<a href="https://github.com/PaddlePaddle/Paddle2ONNX/releases/tag/v1.2.3" target="_blank" rel="noopener noreferrer" class="">当前Paddle2ONNX版本(v1.2.3)</a>现已默认支持动态shape，即 <code>float32[p2o.DynamicDimension.0,3,p2o.DynamicDimension.1,p2o.DynamicDimension.2]</code>，选项 <code>--input_shape_dict</code> 已废弃。如果有shape调整需求可使用如下命令进行Paddle模型输入shape调整。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">python3 -m paddle2onnx.optimize --input_model inference/det_onnx/model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  --output_model inference/det_onnx/model.onnx `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  --input_shape_dict &quot;{&#x27;x&#x27;: [-1,3,-1,-1]}&quot;</span><br></span></code></pre></div></div>
</li>
</ul>
<ul>
<li class="">优化ONNX</li>
</ul>
<p>如你对导出的 ONNX 模型有优化的需求，推荐使用 onnxslim 对模型进行优化:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install onnxslim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">onnxslim input.onnx model.onnx</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-推理预测">3. 推理预测<a href="#3-推理预测" class="hash-link" aria-label="3. 推理预测的直接链接" title="3. 推理预测的直接链接" translate="no">​</a></h2>
<p>需要先安装 opencv、shapely、pyclipper等依赖包, 以中文OCR模型为例，使用 ONNXRuntime 预测可执行如下命令：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install opencv-python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install shapely</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install pyclipper</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install scikit-image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install albumentations</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install lmdb</span><br></span></code></pre></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PaddleOCR</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">python ./tools/infer/predict_system.py --use_gpu=False --use_onnx=True `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--det_model_dir=../model/c.onnx  `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--rec_model_dir=../model/e.onnx  `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--cls_model_dir=../model/d.onnx  `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--image_dir=./deploy/lite/imgs/lite_demo.png</span><br></span></code></pre></div></div>
<p>以中文OCR模型为例，使用 Paddle Inference 预测可执行如下命令：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">cd PaddleOCR</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">python ./tools/infer/predict_system.py --use_gpu=False `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--rec_image_shape=3,48,320 `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--cls_model_dir=../model/ch_ppocr_mobile_v2.0_cls_infer `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--rec_model_dir=../model/ch_PP-OCRv5_rec_infer `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--det_model_dir=../model/ch_PP-OCRv5_det_infer `</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--image_dir=./deploy/lite/imgs/lite_demo.png</span><br></span></code></pre></div></div>
<p>执行命令后在终端会打印出预测的识别信息，并在 <code>./inference_results/</code> 下保存可视化结果。</p>
<p>ONNXRuntime 执行效果：</p>
<div align="center"><img src="./introduction/mixed/inference_results/lite_demo_onnx.png"></div>
<p>Paddle Inference 执行效果：</p>
<div align="center"><img src="./introduction/mixed/inference_results/lite_demo_paddle.png" width="800"></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="q1-小友-onxx-模型支持的-最大-ir-version-">Q1: 小友+ ONXX 模型支持的 最大 IR VERSION ？<a href="#q1-小友-onxx-模型支持的-最大-ir-version-" class="hash-link" aria-label="Q1: 小友+ ONXX 模型支持的 最大 IR VERSION ？的直接链接" title="Q1: 小友+ ONXX 模型支持的 最大 IR VERSION ？的直接链接" translate="no">​</a></h3>
<ul>
<li class="">IR VERSION = 9</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="q2-转换后的模型onnx-runtime加载提示unknown-model-file-format-version">Q2: 转换后的模型，ONNX Runtime加载提示<code>Unknown model file format version</code>?<a href="#q2-转换后的模型onnx-runtime加载提示unknown-model-file-format-version" class="hash-link" aria-label="q2-转换后的模型onnx-runtime加载提示unknown-model-file-format-version的直接链接" title="q2-转换后的模型onnx-runtime加载提示unknown-model-file-format-version的直接链接" translate="no">​</a></h3>
<ul>
<li class="">Paddle2ONNX使用了最新的ONNX协议，导出的模型在使用低版本ONNX Runtime加载时，会出现此问题，可通过如下代码修改模型IR VERSION解决，重新加载新保存的<code>new_model.onnx</code>即可。</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = onnx.load(&quot;model.onnx&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.ir_version = 9</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">onnx.save(model, &quot;new_model.onnx&quot;)</span><br></span></code></pre></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/shelllet/WinUi/edit/main/docs_src/introduction/mixed/paddle2onnx.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/introduction/mixed/glob"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">Glob模式</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/introduction/mixed/wildcard"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">通配符</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-环境准备" class="table-of-contents__link toc-highlight">1. 环境准备</a><ul><li><a href="#python" class="table-of-contents__link toc-highlight">Python</a></li><li><a href="#虚拟环境" class="table-of-contents__link toc-highlight">虚拟环境</a></li><li><a href="#使用-venv-模块python-标准库自带" class="table-of-contents__link toc-highlight">使用 <code>venv</code> 模块（Python 标准库自带）</a></li><li><a href="#paddle" class="table-of-contents__link toc-highlight">Paddle</a></li><li><a href="#4-验证安装" class="table-of-contents__link toc-highlight">4. 验证安装</a></li><li><a href="#5-错误" class="table-of-contents__link toc-highlight">5. 错误</a></li><li><a href="#paddleocr" class="table-of-contents__link toc-highlight">PaddleOCR</a></li><li><a href="#paddle2onnx" class="table-of-contents__link toc-highlight">Paddle2ONNX</a></li></ul></li><li><a href="#2-模型转换" class="table-of-contents__link toc-highlight">2. 模型转换</a></li><li><a href="#3-推理预测" class="table-of-contents__link toc-highlight">3. 推理预测</a><ul><li><a href="#q1-小友-onxx-模型支持的-最大-ir-version-" class="table-of-contents__link toc-highlight">Q1: 小友+ ONXX 模型支持的 最大 IR VERSION ？</a></li><li><a href="#q2-转换后的模型onnx-runtime加载提示unknown-model-file-format-version" class="table-of-contents__link toc-highlight">Q2: 转换后的模型，ONNX Runtime加载提示<code>Unknown model file format version</code>?</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>